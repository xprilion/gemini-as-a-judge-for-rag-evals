{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO6Wn7n7K9ffBzlGNWIwchX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xprilion/gemini-as-a-judge-for-rag-evals/blob/main/Step_3_Perform_Eval.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gemini As A Judge for RAG Evals"
      ],
      "metadata": {
        "id": "7z-PmxJzF3w5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Perform Evaluations"
      ],
      "metadata": {
        "id": "EZa7H_5XF-hb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Load the datasets"
      ],
      "metadata": {
        "id": "HWjUjRwKG8XN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FBLjwX7fCl13",
        "outputId": "ab9319c4-87a8-4433-a02e-25ee4c250597"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-03-01 06:28:46--  https://raw.githubusercontent.com/xprilion/gemini-as-a-judge-for-rag-evals/refs/heads/main/qna_dataset.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 121396 (119K) [text/plain]\n",
            "Saving to: ‘qna_dataset.json’\n",
            "\n",
            "qna_dataset.json    100%[===================>] 118.55K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2025-03-01 06:28:47 (1.20 MB/s) - ‘qna_dataset.json’ saved [121396/121396]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/xprilion/gemini-as-a-judge-for-rag-evals/refs/heads/main/qna_dataset.json"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Packages"
      ],
      "metadata": {
        "id": "i8siIxiEIu-2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install qdrant-client[fastembed]\n",
        "!pip install google-genai"
      ],
      "metadata": {
        "id": "UJy2rKEyIuoK"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imports"
      ],
      "metadata": {
        "id": "rRd-Y1Z4HFWu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "import os\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "from google import genai\n",
        "from google.genai import types\n",
        "from qdrant_client import QdrantClient\n",
        "from qdrant_client.models import Distance, VectorParams\n",
        "import uuid\n",
        "\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u6landw4G5CS",
        "outputId": "c4e67bf1-172b-4e7d-a614-47147898a13a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:502: UserWarning: <built-in function any> is not a Python type (it may be an instance of an object), Pydantic will allow any object with no validation since we cannot even enforce that the input is an instance of the given type. To get rid of this error wrap the type with `pydantic.SkipValidation`.\n",
            "  warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Helpers"
      ],
      "metadata": {
        "id": "6ASIJ0OTXUQ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "collection_name = \"product_reviews\""
      ],
      "metadata": {
        "id": "M1-pzDF5ZMnw"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GEMINI_KEY = userdata.get('GEMINI_API_KEY')\n",
        "gemini_client = genai.Client(\n",
        "    api_key=GEMINI_KEY\n",
        ")"
      ],
      "metadata": {
        "id": "gA4qxypZXVSU"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getGeminiResponse(prompt, max_tokens=8192, response_type=\"text/plain\"):\n",
        "    contents = [\n",
        "        types.Content(\n",
        "            role=\"user\",\n",
        "            parts=[\n",
        "                types.Part.from_text(\n",
        "                    text=prompt\n",
        "                ),\n",
        "            ],\n",
        "        ),\n",
        "    ]\n",
        "    generate_content_config = types.GenerateContentConfig(\n",
        "        temperature=0,\n",
        "        top_p=0.95,\n",
        "        top_k=40,\n",
        "        max_output_tokens=max_tokens,\n",
        "        response_mime_type=response_type,\n",
        "    )\n",
        "    response = gemini_client.models.generate_content(\n",
        "        model=\"gemini-2.0-flash\", contents=contents, config=generate_content_config\n",
        "    )\n",
        "    return response.text"
      ],
      "metadata": {
        "id": "-j7toHuxYuux"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "getGeminiResponse(\"What is 2+3?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Nm6lU5u6Y8WX",
        "outputId": "0404a2da-4ecd-427c-fafa-c15ce3b5f74c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2 + 3 = 5\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### EDA"
      ],
      "metadata": {
        "id": "eRd7drJqHqGh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "qa_dataset = json.load(open(\"qna_dataset.json\"))"
      ],
      "metadata": {
        "id": "8uMt4eB_HfuA"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa_dataset = qa_dataset[0]"
      ],
      "metadata": {
        "id": "tBRn0-xmHjHQ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Connect Qdrant"
      ],
      "metadata": {
        "id": "-RdkaI2JILgj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "QDRANT_URL = \"https://qdrant-1.sg-1.cloudtop.dev\"\n",
        "QDRANT_KEY = userdata.get('PERSONAL_QDRANT_KEY')"
      ],
      "metadata": {
        "id": "_TUJ-RE4H8x2"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qdrant_client = QdrantClient(url=QDRANT_URL, api_key=QDRANT_KEY, port=None)"
      ],
      "metadata": {
        "id": "bCEct2ZjIk_H"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ask questions from the QA dataset"
      ],
      "metadata": {
        "id": "rv7GrVdQKppy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def getRagResponse(question, skip_ai=False):\n",
        "    search_result = qdrant_client.query(collection_name=collection_name, query_text=question)\n",
        "    system_prompt = \"\"\"\n",
        "      You are an intelligent assistant designed to provide accurate and informative answers based on retrieved documents.\n",
        "\n",
        "      Your primary task is to:\n",
        "\n",
        "      Understand the user's query.\n",
        "      Retrieve relevant information from the provided context (documents).\n",
        "      Synthesize the retrieved information into a coherent and accurate response.\n",
        "\n",
        "      documents:\n",
        "\n",
        "      \"\"\"\n",
        "\n",
        "    documents_text = \"\"\n",
        "    matched_ids = []\n",
        "\n",
        "    doc_count = 1\n",
        "    for result in search_result:\n",
        "      documents_text += str(doc_count) + \": \\n\" + result.document + \"\\n\\n\"\n",
        "      matched_ids.append(result.metadata[\"index\"])\n",
        "      doc_count += 1\n",
        "\n",
        "    users_query = \"\\n\\n The user is asking: \" + question\n",
        "\n",
        "    prompt = system_prompt + documents_text + users_query\n",
        "\n",
        "    if skip_ai:\n",
        "        return prompt, matched_ids\n",
        "\n",
        "    response = getGeminiResponse(prompt)\n",
        "\n",
        "    return response, matched_ids"
      ],
      "metadata": {
        "id": "kXzrjfPKaYcT"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa_dataset[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ul9Zh50ybG1i",
        "outputId": "3349a3df-dac5-426d-8b60-1ae0a4fa347d"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'answer': 'The description and review mention the high-density foam cover, smooth application, lightweight frame, and easy cleaning.',\n",
              " 'matched_indexes': [272, 276],\n",
              " 'question': 'What are the features of the 9-inch paint roller?'}"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_query = \"What are the key features of the heavy-duty workbench?\""
      ],
      "metadata": {
        "id": "MK2JzpMoarKf"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result, indexes = getRagResponse(user_query, True)"
      ],
      "metadata": {
        "id": "aEJ0VaK-awsp"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "indexes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXF-0Dq6a9k3",
        "outputId": "95f873cf-2d4c-4253-9cdf-eed88a7423d9"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[355, 357, 351, 358, 350, 354, 352, 359, 353, 356]"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evals = []\n",
        "matches = 0"
      ],
      "metadata": {
        "id": "dZxwbQkzbMh3"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for eval_ques in tqdm(qa_dataset):\n",
        "    evals.append({\"query\": eval_ques, \"result\": len(intersection) > 0})\n",
        "    query = eval_ques[\"question\"]\n",
        "    result, indexes = getRagResponse(query, True)\n",
        "    intersection = list(set(indexes) & set(eval_ques[\"matched_indexes\"]))\n",
        "    if len(eval_ques[\"matched_indexes\"]) > 0 and len(intersection) > 0:\n",
        "        matches += 1\n",
        "    if len(eval_ques[\"matched_indexes\"]) == 0 and len(indexes) == 0:\n",
        "        matches += 1\n",
        "    if len(evals) % 100 == 0:\n",
        "        print(f\"Checks: {matches}/{len(evals)} of {len(qa_dataset)}\")"
      ],
      "metadata": {
        "id": "HMJx7430a96Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3feb034-21f8-47ab-aee2-68d52ac79c1b"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:02<00:00,  9.15it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "matches"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "owPW2z7WdBbQ",
        "outputId": "ce6be272-c0cd-4552-dd9f-a6939802e019"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Accuracy"
      ],
      "metadata": {
        "id": "OA0NkS1Dem0m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = matches / len(evals)\n",
        "accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLYuNOsbemjY",
        "outputId": "664ac2da-4cef-47d6-863f-144226e859ea"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rn_dCeD9dGWD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}